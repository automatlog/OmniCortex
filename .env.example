# =============================================================================
# OmniCortex Environment Variables Template
# Copy this file to .env and update with your values
# =============================================================================

# =============================================================================
# DATABASE (REQUIRED)
# =============================================================================
DATABASE_URL=postgresql://postgres:YOUR_PASSWORD@localhost:5432/omnicortex

# =============================================================================
# CLICKHOUSE ANALYTICS (Optional)
# =============================================================================
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your_password
CLICKHOUSE_DB=omnicortex

# =============================================================================
# LLM MODELS
# =============================================================================
# Ollama (Local, Fast, Free) - DEFAULT DEV PROFILE
VLLM_BASE_URL=http://localhost:11434/v1
VLLM_MODEL=llama3.1:8b
VLLM_API_KEY=not-needed

# OpenAI (Cloud, Reliable, Paid)
# VLLM_BASE_URL=https://api.openai.com/v1
# VLLM_MODEL=gpt-4o-mini
# VLLM_API_KEY=your-openai-api-key-here

# Groq (Cloud, Fast, Free tier available)
# VLLM_BASE_URL=https://api.groq.com/openai/v1
# VLLM_MODEL=llama-3.3-70b-versatile
# VLLM_API_KEY=your-groq-api-key-here

# vLLM Ubuntu profile (Meta Llama 3.1 8B)
# VLLM_BASE_URL=http://localhost:8080/v1
# VLLM_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
# VLLM_API_KEY=not-needed

# Optional secondary selector entry
# LLAMA_BASE_URL=http://localhost:8080/v1
# LLAMA_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
# --- NOTE: Uncommenting the Ubuntu profile below will override the Ollama VLLM_* variables above. ---
# To use the Ubuntu profile, comment out the Ollama section first.
# VLLM_UBUNTU_BASE_URL=http://localhost:8080/v1
# VLLM_UBUNTU_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
# VLLM_UBUNTU_API_KEY=not-needed
# Voice Model (PersonaPlex)
PERSONAPLEX_MODEL=nvidia/personaplex-7b-v1

LLM_TEMPERATURE=0.6

# =============================================================================
# RAG SETTINGS
# =============================================================================
# Embeddings (384 dimensions)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Chunking
CHUNK_SIZE=700
CHUNK_OVERLAP=120
USE_SEMANTIC_CHUNKING=false

# Retrieval
TOP_K_RESULTS=4

# Reranker (DISABLE for faster responses)
USE_RERANKER=false
RERANKER_MODEL_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2

# =============================================================================
# MEMORY
# =============================================================================
DEFAULT_MAX_HISTORY=5
MAX_HISTORY_LIMIT=20

# =============================================================================
# VOICE ENGINE (LiquidAI)
# =============================================================================
VOICE_MODEL=LiquidAI/LFM2.5-Audio-1.5B
VOICE_MAX_INSTANCES=8

# =============================================================================
# WHATSAPP (Optional)
# =============================================================================
WHATSAPP_ACCESS_TOKEN=your_whatsapp_token_here
WHATSAPP_PHONE_ID=your_phone_id_here
WHATSAPP_API_VERSION=v24.0
WHATSAPP_VERIFY_TOKEN=omnicortex_token

# =============================================================================
# VOICE ENGINE
# =============================================================================
MOSHI_ENABLED=true
TTS_PROVIDER=moshi

# =============================================================================
# HUGGINGFACE (Required for gated models like Llama)
# =============================================================================
HUGGING_FACE_HUB_TOKEN=your_huggingface_token_here

# =============================================================================
# STORAGE
# =============================================================================
STORAGE_PATH=storage
