# =============================================================================
# OmniCortex Environment Variables Template
# Copy this file to .env and update with your values
# =============================================================================

# =============================================================================
# DATABASE (REQUIRED)
# =============================================================================
DATABASE_URL=postgresql://postgres:YOUR_PASSWORD@localhost:5432/omnicortex

# =============================================================================
# CLICKHOUSE ANALYTICS (Optional)
# =============================================================================
CLICKHOUSE_HOST=localhost
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your_password
CLICKHOUSE_DB=omnicortex

# =============================================================================
# LLM MODELS
# =============================================================================
# vLLM (Local, OpenAI-compatible) - DEFAULT DEV PROFILE
VLLM_BASE_URL=http://localhost:8080/v1
VLLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
VLLM_API_KEY=not-needed

# OpenAI (Cloud, Reliable, Paid)
# VLLM_BASE_URL=https://api.openai.com/v1
# VLLM_MODEL=gpt-4o-mini
# VLLM_API_KEY=your-openai-api-key-here

# Groq (Cloud, Fast, Free tier available)
# VLLM_BASE_URL=https://api.groq.com/openai/v1
# VLLM_MODEL=llama-3.3-70b-versatile
# VLLM_API_KEY=your-groq-api-key-here

# vLLM Ubuntu profile (Meta Llama 3.1 8B)
# VLLM_BASE_URL=http://localhost:8080/v1
# VLLM_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
# VLLM_API_KEY=not-needed

# Optional secondary selector entry (same local vLLM endpoint)
# LLAMA_BASE_URL=http://localhost:8080/v1
# LLAMA_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
# --- NOTE: Uncommenting the Ubuntu profile below will override the default VLLM_* variables above. ---
# VLLM_UBUNTU_BASE_URL=http://localhost:8080/v1
# VLLM_UBUNTU_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
# VLLM_UBUNTU_API_KEY=not-needed
# Voice Model (PersonaPlex)
PERSONAPLEX_MODEL=nvidia/personaplex-7b-v1

LLM_TEMPERATURE=0.6

# =============================================================================
# RAG SETTINGS
# =============================================================================
# Embeddings (384 dimensions)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Chunking
CHUNK_SIZE=700
CHUNK_OVERLAP=120
USE_SEMANTIC_CHUNKING=false

# Retrieval
TOP_K_RESULTS=4

# Reranker (DISABLE for faster responses)
USE_RERANKER=false
RERANKER_MODEL_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2

# =============================================================================
# MEMORY
# =============================================================================
DEFAULT_MAX_HISTORY=5
MAX_HISTORY_LIMIT=20


# =============================================================================
# WHATSAPP (Optional)
# =============================================================================
WHATSAPP_ACCESS_TOKEN=your_whatsapp_token_here
WHATSAPP_PHONE_ID=your_phone_id_here
WHATSAPP_API_VERSION=v24.0
WHATSAPP_VERIFY_TOKEN=omnicortex_token

# =============================================================================
# VOICE ENGINE
# =============================================================================
MOSHI_ENABLED=true
TTS_PROVIDER=moshi

# =============================================================================
# HUGGINGFACE (Required for gated models like Llama)
# =============================================================================
HUGGING_FACE_HUB_TOKEN=your_huggingface_token_here

# =============================================================================
# STORAGE
# =============================================================================
STORAGE_PATH=storage

# =============================================================================
# AUTH (REQUIRED - protects API key generation endpoints)
# =============================================================================
## WARNING: THIS VALUE MUST BE CHANGED BEFORE DEPLOYMENT!
# MASTER_API_KEY protects API key generation endpoints. Set a strong, unique value.
MASTER_API_KEY=CHANGE_ME_MASTER_API_KEY_MUST_BE_REPLACED

# =============================================================================
# CORS (comma-separated allowed origins)
# =============================================================================
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000,http://localhost:3001

# =============================================================================
# WHATSAPP FLOW MODE (draft or published)
# =============================================================================
WHATSAPP_FLOW_MODE=published
